# MultiTalk V98 - Fixed pip installation issues
FROM pytorch/pytorch:2.1.2-cuda12.1-cudnn8-devel

# System dependencies
ENV DEBIAN_FRONTEND=noninteractive
RUN apt-get update && apt-get install -y \
    git \
    ffmpeg \
    gcc \
    g++ \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Environment variables - use /tmp for cache to avoid permission issues
ENV PYTHONPATH=/app/multitalk_official:/app:/runpod-volume/models
ENV HF_HOME=/tmp/huggingface
ENV TRANSFORMERS_CACHE=/tmp/huggingface
ENV MODEL_PATH=/runpod-volume/models
ENV PYTHONUNBUFFERED=1

WORKDIR /app

# Install core dependencies first
RUN pip install --no-cache-dir \
    runpod==1.7.3 \
    numpy==1.24.3 \
    scipy==1.10.1 \
    torch==2.1.2 \
    transformers==4.43.3 \
    tokenizers==0.19.1 \
    librosa==0.10.2 \
    soundfile==0.12.1 \
    diffusers>=0.31.0 \
    accelerate>=1.1.1 \
    safetensors>=0.4.3 \
    opencv-python>=4.9.0 \
    imageio>=2.30.0 \
    huggingface-hub==0.23.5 \
    einops \
    rotary-embedding-torch \
    tensorboardX \
    omegaconf \
    easydict \
    ftfy \
    timm \
    sentencepiece \
    peft \
    boto3 \
    moviepy \
    imageio-ffmpeg \
    Pillow \
    torchaudio \
    torchvision \
    pydub \
    av \
    pyloudnorm

# Install xfuser separately
RUN pip install --no-cache-dir xfuser>=0.4.1

# Install flash-attn separately with specific flags
RUN pip install flash-attn --no-build-isolation

# Clone MultiTalk repository
RUN mkdir -p /app/multitalk_official && \
    cd /app/multitalk_official && \
    git clone https://github.com/MeiGen-AI/MultiTalk.git . && \
    echo "MultiTalk repository cloned successfully"

# Create handler based on cog-MultiTalk approach
RUN cat > /app/handler.py << 'EOF'
import runpod
import os
import sys
import json
import time
import torch
import base64
import boto3
import tempfile
import traceback
import warnings
from pathlib import Path
from io import BytesIO
from PIL import Image
import numpy as np
import soundfile as sf
import librosa
import pyloudnorm as pyln
from transformers import Wav2Vec2FeatureExtractor

# Add MultiTalk to path
sys.path.insert(0, '/app/multitalk_official')

print("="*50)
print("V98: MultiTalk Handler Starting")
print(f"Python: {sys.version}")
print(f"PyTorch: {torch.__version__}")
print(f"CUDA Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA Device: {torch.cuda.get_device_name(0)}")
print("="*50)

# S3 utilities
def download_from_s3(s3_url):
    """Download file from S3 URL"""
    try:
        if s3_url.startswith("s3://"):
            parts = s3_url[5:].split('/', 1)
            bucket = parts[0]
            key = parts[1] if len(parts) > 1 else ""
        else:
            return None
        
        s3_client = boto3.client('s3')
        temp_file = tempfile.NamedTemporaryFile(delete=False)
        s3_client.download_file(bucket, key, temp_file.name)
        return temp_file.name
        
    except Exception as e:
        print(f"V98: S3 download error: {e}")
        return None

def upload_to_s3(file_path, s3_key):
    """Upload file to S3"""
    try:
        aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')
        aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')
        aws_region = os.getenv('AWS_REGION', 'us-east-1')
        bucket_name = os.getenv('AWS_S3_BUCKET_NAME')
        
        if not all([aws_access_key, aws_secret_key, bucket_name]):
            print("V98: Missing S3 credentials")
            return None
        
        s3_client = boto3.client(
            's3',
            aws_access_key_id=aws_access_key,
            aws_secret_access_key=aws_secret_key,
            region_name=aws_region
        )
        
        s3_client.upload_file(file_path, bucket_name, s3_key)
        url = f"https://{bucket_name}.s3.{aws_region}.amazonaws.com/{s3_key}"
        return url
        
    except Exception as e:
        print(f"V98: S3 upload error: {e}")
        return None

def process_input_file(input_ref, file_type):
    """Process input that could be S3 URL, base64, or local file"""
    try:
        if isinstance(input_ref, str):
            # S3 URL
            if input_ref.startswith("s3://"):
                return download_from_s3(input_ref)
            
            # Base64 data
            elif input_ref.startswith(f"data:{file_type}"):
                header, data = input_ref.split(',', 1)
                decoded_data = base64.b64decode(data)
                
                ext = ".wav" if file_type == "audio" else ".png"
                temp_file = tempfile.NamedTemporaryFile(suffix=ext, delete=False)
                temp_file.write(decoded_data)
                temp_file.close()
                return temp_file.name
            
            # Local file in models directory
            else:
                model_path = Path("/runpod-volume/models")
                
                # Try exact match first
                exact_path = model_path / input_ref
                if exact_path.exists():
                    return str(exact_path)
                
                # Search for file
                matches = list(model_path.rglob(input_ref))
                if matches:
                    return str(matches[0])
                
                # Try without extension
                name_only = Path(input_ref).stem
                for ext in ['wav', 'mp3', 'png', 'jpg', 'jpeg']:
                    matches = list(model_path.rglob(f"{name_only}.{ext}"))
                    if matches:
                        return str(matches[0])
        
        return None
        
    except Exception as e:
        print(f"V98: Error processing input: {e}")
        return None

# Global variables for models
multitalk_pipeline = None
wav2vec2_model = None

def load_multitalk_models():
    """Load MultiTalk models following cog-MultiTalk approach"""
    global multitalk_pipeline, wav2vec2_model
    
    print("V98: Loading MultiTalk models...")
    try:
        # Test imports first
        print("V98: Testing imports...")
        
        try:
            import wan
            print("V98: ✓ wan imported successfully")
        except ImportError as e:
            print(f"V98: ✗ wan import failed: {e}")
            return False
            
        try:
            from wan.configs import SIZE_CONFIGS, SUPPORTED_SIZES, WAN_CONFIGS
            print("V98: ✓ wan.configs imported successfully")
        except ImportError as e:
            print(f"V98: ✗ wan.configs import failed: {e}")
            return False
        
        try:
            from src.audio_analysis.wav2vec2 import Wav2Vec2Model
            print("V98: ✓ custom Wav2Vec2Model imported successfully")
        except ImportError as e:
            print(f"V98: ✗ custom Wav2Vec2Model import failed: {e}")
            print("V98: Falling back to transformers Wav2Vec2Model")
            from transformers import Wav2Vec2Model
        
        # Check model directory
        model_path = Path("/runpod-volume/models")
        checkpoint_dir = model_path / "wan2.1-i2v-14b-480p"
        
        if not checkpoint_dir.exists():
            print(f"V98: Checkpoint directory not found: {checkpoint_dir}")
            return False
        
        # Initialize device
        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        print(f"V98: Using device: {device}")
        
        # Load Wav2Vec2 model
        print("V98: Loading Wav2Vec2 model...")
        wav2vec2_model = Wav2Vec2Model.from_pretrained(
            "facebook/wav2vec2-base-960h",
            cache_dir="/tmp/huggingface"
        )
        wav2vec2_model = wav2vec2_model.to(device)
        wav2vec2_model.eval()
        print("V98: ✓ Wav2Vec2 model loaded")
        
        # Initialize MultiTalk pipeline
        print("V98: Initializing MultiTalk pipeline...")
        cfg = WAN_CONFIGS["MultiTalk-I2V"]
        
        multitalk_pipeline = wan.MultiTalkPipeline(
            config=cfg,
            checkpoint_dir=str(checkpoint_dir),
            device_id=device,
            rank=0,
            world_size=1,
            dtype=torch.float16
        )
        
        print("V98: ✓ MultiTalk pipeline initialized")
        return True
        
    except Exception as e:
        print(f"V98: Error loading models: {e}")
        traceback.print_exc()
        return False

def process_audio(audio_path):
    """Process audio following cog-MultiTalk approach"""
    try:
        print(f"V98: Processing audio: {audio_path}")
        
        # Load audio
        audio_data, sr = librosa.load(audio_path, sr=None)
        print(f"V98: Audio loaded - duration: {len(audio_data)/sr:.2f}s, sample rate: {sr}")
        
        # Normalize loudness
        meter = pyln.Meter(sr)
        loudness = meter.integrated_loudness(audio_data)
        target_loudness = -23.0
        audio_data = pyln.normalize.loudness(audio_data, loudness, target_loudness)
        print(f"V98: Audio loudness normalized from {loudness:.2f} to {target_loudness}")
        
        # Get audio features using Wav2Vec2
        if wav2vec2_model is not None:
            device = next(wav2vec2_model.parameters()).device
            inputs = torch.from_numpy(audio_data).float().unsqueeze(0).to(device)
            
            with torch.no_grad():
                outputs = wav2vec2_model(inputs)
                audio_features = outputs.last_hidden_state
            
            print(f"V98: Audio features extracted - shape: {audio_features.shape}")
            return audio_features
        else:
            print("V98: Wav2Vec2 model not loaded, using dummy features")
            return torch.randn(1, 100, 768)
            
    except Exception as e:
        print(f"V98: Error processing audio: {e}")
        traceback.print_exc()
        return None

def generate_multitalk_video(audio_path, image_path, prompt=None, audio2_path=None):
    """Generate video using MultiTalk pipeline"""
    try:
        print("V98: Generating MultiTalk video...")
        
        # Load models if not already loaded
        if multitalk_pipeline is None:
            print("V98: Pipeline not loaded, attempting to load...")
            if not load_multitalk_models():
                print("V98: Failed to load models, using fallback")
                return create_fallback_video(audio_path, image_path)
        
        # Process audio
        audio_features = process_audio(audio_path)
        if audio_features is None:
            print("V98: Audio processing failed")
            return create_fallback_video(audio_path, image_path)
        
        # Load and process image
        image = Image.open(image_path).convert("RGB")
        print(f"V98: Image loaded - size: {image.size}")
        
        # Prepare input data
        input_data = {
            "prompt": prompt or "A person talking naturally",
            "image": image,
            "audio_features": audio_features,
            "num_frames": 81,
            "num_inference_steps": 30,
            "guidance_scale": 7.5,
            "audio_guidance_scale": 3.0,
            "seed": 42
        }
        
        # Generate video
        print("V98: Running MultiTalk pipeline...")
        with torch.cuda.amp.autocast():
            video = multitalk_pipeline.generate(
                input_data,
                size_bucket="480p"
            )
        
        # Save video
        output_path = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False).name
        
        # Save using wan utils
        from wan.utils.multitalk_utils import save_video_ffmpeg
        save_video_ffmpeg(video, output_path, fps=25)
        
        print(f"V98: Video saved to {output_path}")
        return output_path
        
    except Exception as e:
        print(f"V98: Error generating video: {e}")
        traceback.print_exc()
        
        # Fallback to simple video
        print("V98: Using fallback video generation")
        return create_fallback_video(audio_path, image_path)

def create_fallback_video(audio_path, image_path):
    """Create a fallback video when MultiTalk fails"""
    try:
        import cv2
        from moviepy.editor import VideoFileClip, AudioFileClip
        
        print("V98: Creating fallback video...")
        
        img = cv2.imread(image_path) if image_path else np.zeros((480, 854, 3), dtype=np.uint8)
        if img is None:
            img = np.zeros((480, 854, 3), dtype=np.uint8)
            img[:] = (100, 150, 200)
        
        temp_video = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False).name
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(temp_video, fourcc, 25.0, (img.shape[1], img.shape[0]))
        
        for i in range(75):
            frame = img.copy()
            cv2.putText(frame, f"MultiTalk V98 - Frame {i+1}", (50, 50), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            out.write(frame)
        
        out.release()
        
        if audio_path and os.path.exists(audio_path):
            try:
                video_clip = VideoFileClip(temp_video)
                audio_clip = AudioFileClip(audio_path)
                
                if audio_clip.duration > video_clip.duration:
                    audio_clip = audio_clip.subclip(0, video_clip.duration)
                
                final_output = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False).name
                final_clip = video_clip.set_audio(audio_clip)
                final_clip.write_videofile(final_output, codec='libx264', audio_codec='aac', verbose=False, logger=None)
                
                video_clip.close()
                audio_clip.close()
                final_clip.close()
                os.unlink(temp_video)
                
                return final_output
            except Exception as e:
                print(f"V98: Error adding audio to fallback: {e}")
                return temp_video
        
        return temp_video
        
    except Exception as e:
        print(f"V98: Error creating fallback video: {e}")
        traceback.print_exc()
        return None

def handler(job):
    """V98 Handler with fixed dependencies"""
    print(f"V98: Received job: {job}")
    
    job_input = job.get("input", {})
    action = job_input.get("action", "generate")
    
    try:
        if action == "generate":
            # Get inputs
            audio_1 = job_input.get("audio_1")
            audio_2 = job_input.get("audio_2")
            condition_image = job_input.get("condition_image")
            prompt = job_input.get("prompt", "A person talking naturally")
            output_format = job_input.get("output_format", "s3")
            s3_key = job_input.get("s3_output_key", f"multitalk-out/output-{int(time.time())}.mp4")
            
            if not audio_1 or not condition_image:
                return {
                    "output": {
                        "status": "error",
                        "error": "Missing required inputs: audio_1 and condition_image"
                    }
                }
            
            # Process inputs
            audio_path = process_input_file(audio_1, "audio")
            audio2_path = process_input_file(audio_2, "audio") if audio_2 else None
            image_path = process_input_file(condition_image, "image")
            
            if not audio_path or not image_path:
                return {
                    "output": {
                        "status": "error",
                        "error": "Failed to process input files"
                    }
                }
            
            # Generate video
            video_path = generate_multitalk_video(audio_path, image_path, prompt, audio2_path)
            
            if not video_path or not os.path.exists(video_path):
                return {
                    "output": {
                        "status": "error",
                        "error": "Failed to generate video"
                    }
                }
            
            print(f"V98: Video generated: {video_path}, size: {os.path.getsize(video_path)} bytes")
            
            # Handle output format
            if output_format == "s3":
                s3_key = s3_key.replace("{version}", "v98")
                s3_key = s3_key.replace("{int(time.time())}", str(int(time.time())))
                
                video_url = upload_to_s3(video_path, s3_key)
                
                if video_url:
                    result = {
                        "status": "completed",
                        "video_url": video_url,
                        "s3_key": s3_key,
                        "message": "MultiTalk video generated successfully (V98)"
                    }
                else:
                    with open(video_path, 'rb') as f:
                        video_base64 = base64.b64encode(f.read()).decode('utf-8')
                    result = {
                        "status": "completed",
                        "video_base64": video_base64,
                        "message": "MultiTalk video generated (S3 upload failed)"
                    }
            else:
                with open(video_path, 'rb') as f:
                    video_base64 = base64.b64encode(f.read()).decode('utf-8')
                result = {
                    "status": "completed",
                    "video_base64": video_base64,
                    "message": "MultiTalk video generated successfully (V98)"
                }
            
            # Cleanup
            try:
                os.unlink(video_path)
                if audio_path.startswith('/tmp'):
                    os.unlink(audio_path)
                if image_path.startswith('/tmp'):
                    os.unlink(image_path)
                if audio2_path and audio2_path.startswith('/tmp'):
                    os.unlink(audio2_path)
            except:
                pass
            
            return {"output": result}
        
        elif action == "model_check":
            model_path = Path("/runpod-volume/models")
            model_info = {
                "network_volume_mounted": os.path.exists("/runpod-volume"),
                "models_directory_exists": model_path.exists(),
                "s3_configured": all([
                    os.getenv('AWS_ACCESS_KEY_ID'),
                    os.getenv('AWS_SECRET_ACCESS_KEY'),
                    os.getenv('AWS_S3_BUCKET_NAME')
                ]),
                "cuda_available": torch.cuda.is_available(),
                "device": str(torch.cuda.get_device_name(0) if torch.cuda.is_available() else "cpu"),
            }
            
            # Check imports
            try:
                import xfuser
                model_info["xfuser_available"] = True
                model_info["xfuser_version"] = xfuser.__version__
            except ImportError:
                model_info["xfuser_available"] = False
                
            try:
                import flash_attn
                model_info["flash_attn_available"] = True
            except ImportError:
                model_info["flash_attn_available"] = False
            
            if model_path.exists():
                checkpoint_dir = model_path / "wan2.1-i2v-14b-480p"
                model_info["wan_checkpoint_exists"] = checkpoint_dir.exists()
                
                files = list(model_path.rglob("*"))
                model_info["total_files"] = len([f for f in files if f.is_file()])
            
            return {
                "output": {
                    "status": "ready",
                    "message": "V98 MultiTalk handler ready (fixed dependencies)",
                    "version": "98",
                    "model_info": model_info
                }
            }
        
        else:
            return {
                "output": {
                    "status": "error",
                    "error": f"Unknown action: {action}"
                }
            }
            
    except Exception as e:
        print(f"V98: Handler error: {e}")
        traceback.print_exc()
        return {
            "output": {
                "status": "error",
                "error": str(e),
                "traceback": traceback.format_exc()
            }
        }

# Pre-load models if possible
if os.path.exists("/runpod-volume/models"):
    print("V98: Attempting to pre-load models...")
    load_multitalk_models()

# Start handler
print("V98: Starting RunPod serverless handler...")
runpod.serverless.start({"handler": handler})
EOF

CMD ["python", "-u", "/app/handler.py"]