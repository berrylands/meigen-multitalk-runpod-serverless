# MultiTalk V150 - Graceful error handling with proper dependencies
FROM pytorch/pytorch:2.4.0-cuda12.1-cudnn9-runtime AS base

# Install runtime dependencies
ENV DEBIAN_FRONTEND=noninteractive TZ=UTC
RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone && \
    apt-get update && apt-get install -y --no-install-recommends \
        git \
        ffmpeg \
        curl && \
    rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*

WORKDIR /app

# Set environment variables
ENV PYTHONPATH=/app/cog_multitalk_reference:/app:/runpod-volume/models \
    HF_HOME=/runpod-volume/huggingface \
    TRANSFORMERS_CACHE=/runpod-volume/huggingface \
    MODEL_PATH=/runpod-volume/models \
    PYTHONUNBUFFERED=1

# Copy and extract reference implementation
COPY cog_multitalk_reference.tar.gz /app/
RUN tar -xzf cog_multitalk_reference.tar.gz && \
    rm cog_multitalk_reference.tar.gz && \
    echo "Reference implementation extracted"

# Install pget utility
RUN curl -o /usr/local/bin/pget -L "https://github.com/replicate/pget/releases/latest/download/pget_$(uname -s)_$(uname -m)" && \
    chmod +x /usr/local/bin/pget

# Keep PyTorch versions that come with the base image
# Install core dependencies without version conflicts
RUN pip install --no-cache-dir \
    "transformers>=4.49.0" \
    "diffusers>=0.31.0" \
    "accelerate>=1.1.1" \
    "safetensors>=0.3.1" \
    "huggingface-hub>=0.19.0"

# Install essential utilities
RUN pip install --no-cache-dir \
    "numpy>=1.23.5,<2" \
    "opencv-python>=4.9.0.80" \
    "einops>=0.8.0" \
    "tqdm"

# Install audio/video processing without version conflicts
RUN pip install --no-cache-dir \
    "imageio" \
    "imageio-ffmpeg" \
    "soundfile>=0.12.1" \
    "librosa>=0.10.0" \
    "pyloudnorm"

# Install basic utilities
RUN pip install --no-cache-dir \
    "scipy" \
    "scikit-image" \
    "easydict" \
    "ftfy" \
    "loguru" \
    "requests" \
    "pyyaml" \
    "packaging" \
    "ninja"

# Install xformers for attention optimization
RUN pip install --no-cache-dir "xformers>=0.0.28"

# Install xfuser WITHOUT its heavy dependencies to avoid conflicts
RUN pip install --no-cache-dir --no-deps "xfuser==0.4.1"

# Install yunchang from source WITHOUT flash-attn dependency
RUN git clone https://github.com/feifeibear/long-context-attention.git && \
    cd long-context-attention && \
    pip install --no-deps -e . && \
    cd .. && \
    echo "yunchang installed without dependencies"

# Install distvae without dependencies
RUN pip install --no-cache-dir --no-deps distvae

# Install RunPod and S3 dependencies
RUN pip install --no-cache-dir \
    "boto3" \
    "botocore" \
    "runpod==1.7.3" \
    "Pillow"

# Copy our handler files
COPY multitalk_reference_wrapper_v150.py /app/multitalk_reference_wrapper.py
COPY handler_v150_graceful.py /app/handler.py
COPY s3_handler.py /app/

# Create startup diagnostics script
RUN cat > /app/startup_diagnostics.py << 'EOF'
#!/usr/bin/env python3
"""
V150 Startup Diagnostics - Test all dependencies and provide detailed feedback
"""

import sys
import os
import traceback
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

def test_basic_imports():
    """Test basic Python imports"""
    logger.info("=== Testing Basic Imports ===")
    
    imports = [
        ("torch", "PyTorch"),
        ("numpy", "NumPy"),
        ("transformers", "Transformers"),
        ("diffusers", "Diffusers"),
        ("accelerate", "Accelerate"),
        ("soundfile", "SoundFile"),
        ("librosa", "Librosa"),
        ("PIL", "Pillow"),
        ("cv2", "OpenCV"),
        ("boto3", "Boto3"),
        ("runpod", "RunPod")
    ]
    
    success_count = 0
    for module, name in imports:
        try:
            __import__(module)
            logger.info(f"✅ {name} imported successfully")
            success_count += 1
        except Exception as e:
            logger.error(f"❌ {name} import failed: {e}")
    
    logger.info(f"Basic imports: {success_count}/{len(imports)} successful")
    return success_count == len(imports)

def test_advanced_imports():
    """Test advanced/optional imports"""
    logger.info("=== Testing Advanced Imports ===")
    
    imports = [
        ("xformers", "XFormers"),
        ("xfuser", "XFuser"), 
        ("yunchang", "YunChang"),
        ("distvae", "DistVAE")
    ]
    
    success_count = 0
    for module, name in imports:
        try:
            __import__(module)
            logger.info(f"✅ {name} imported successfully")
            success_count += 1
        except Exception as e:
            logger.error(f"⚠️  {name} import failed: {e}")
    
    logger.info(f"Advanced imports: {success_count}/{len(imports)} successful")
    return success_count

def test_wan_import():
    """Test wan module import"""
    logger.info("=== Testing WAN Module ===")
    
    try:
        sys.path.insert(0, '/app/cog_multitalk_reference')
        import wan
        logger.info("✅ WAN module imported successfully")
        return True
    except Exception as e:
        logger.error(f"❌ WAN module import failed: {e}")
        logger.error(traceback.format_exc())
        return False

def test_model_paths():
    """Test model paths and network volume"""
    logger.info("=== Testing Model Paths ===")
    
    paths = [
        ("/runpod-volume", "Network volume root"),
        ("/runpod-volume/models", "Models directory"),
        ("/runpod-volume/huggingface", "HuggingFace cache"),
        ("/app/cog_multitalk_reference", "Reference implementation")
    ]
    
    success_count = 0
    for path, name in paths:
        if os.path.exists(path):
            logger.info(f"✅ {name} exists: {path}")
            success_count += 1
        else:
            logger.warning(f"⚠️  {name} missing: {path}")
    
    logger.info(f"Model paths: {success_count}/{len(paths)} available")
    return success_count

def test_gpu_access():
    """Test GPU access"""
    logger.info("=== Testing GPU Access ===")
    
    try:
        import torch
        if torch.cuda.is_available():
            device_count = torch.cuda.device_count()
            current_device = torch.cuda.current_device()
            device_name = torch.cuda.get_device_name(current_device)
            logger.info(f"✅ GPU available: {device_name} (device {current_device}/{device_count})")
            return True
        else:
            logger.warning("⚠️  GPU not available, using CPU")
            return False
    except Exception as e:
        logger.error(f"❌ GPU test failed: {e}")
        return False

def main():
    """Run all diagnostic tests"""
    logger.info("=" * 80)
    logger.info("V150 Container Startup Diagnostics")
    logger.info("=" * 80)
    
    # Test basic imports
    basic_ok = test_basic_imports()
    
    # Test advanced imports  
    advanced_count = test_advanced_imports()
    
    # Test WAN import
    wan_ok = test_wan_import()
    
    # Test model paths
    paths_count = test_model_paths()
    
    # Test GPU access
    gpu_ok = test_gpu_access()
    
    # Summary
    logger.info("=" * 80)
    logger.info("DIAGNOSTIC SUMMARY")
    logger.info("=" * 80)
    logger.info(f"Basic imports: {'✅ PASS' if basic_ok else '❌ FAIL'}")
    logger.info(f"Advanced imports: {advanced_count}/4 available")
    logger.info(f"WAN module: {'✅ PASS' if wan_ok else '❌ FAIL'}")
    logger.info(f"Model paths: {paths_count}/4 available")
    logger.info(f"GPU access: {'✅ PASS' if gpu_ok else '⚠️  CPU ONLY'}")
    
    # Overall assessment
    if basic_ok and wan_ok:
        logger.info("🎉 Container should start successfully!")
        return 0
    else:
        logger.error("💥 Container may fail to start!")
        return 1

if __name__ == "__main__":
    sys.exit(main())
EOF

# Run startup diagnostics
RUN python /app/startup_diagnostics.py

CMD ["python", "-u", "/app/handler.py"]