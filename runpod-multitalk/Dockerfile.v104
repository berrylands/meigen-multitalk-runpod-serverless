# MultiTalk V104 - Build xfuser in stages to manage space
FROM pytorch/pytorch:2.1.2-cuda12.1-cudnn8-devel AS builder

# System dependencies
ENV DEBIAN_FRONTEND=noninteractive
RUN apt-get update && apt-get install -y \
    git \
    gcc \
    g++ \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /tmp

# Clone and build xfuser
RUN git clone https://github.com/xdit-project/xDiT.git && \
    cd xDiT && \
    pip wheel --no-deps -w /tmp/wheels . && \
    pip wheel -w /tmp/wheels \
        "beautifulsoup4>=4.12.3" \
        "yunchang>=0.6.0" \
        "distvae"

# Main image
FROM pytorch/pytorch:2.1.2-cuda12.1-cudnn8-devel

# System dependencies
ENV DEBIAN_FRONTEND=noninteractive
RUN apt-get update && apt-get install -y \
    git \
    ffmpeg \
    gcc \
    g++ \
    build-essential \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Environment variables
ENV PYTHONPATH=/app/multitalk_official:/app:/runpod-volume/models
ENV HF_HOME=/tmp/huggingface
ENV TRANSFORMERS_CACHE=/tmp/huggingface
ENV MODEL_PATH=/runpod-volume/models
ENV PYTHONUNBUFFERED=1

WORKDIR /app

# Copy wheels from builder
COPY --from=builder /tmp/wheels /tmp/wheels

# Install core dependencies
RUN pip install --no-cache-dir \
    runpod==1.7.3 \
    numpy==1.24.3 \
    scipy==1.10.1 \
    torch==2.1.2 \
    transformers==4.43.3 \
    tokenizers==0.19.1 \
    librosa==0.10.2 \
    soundfile==0.12.1 \
    diffusers>=0.31.0 \
    accelerate>=1.1.1 \
    safetensors>=0.4.3 \
    opencv-python>=4.9.0 \
    imageio>=2.30.0 \
    huggingface-hub==0.23.5 \
    einops \
    rotary-embedding-torch \
    tensorboardX \
    omegaconf \
    easydict \
    ftfy \
    timm \
    sentencepiece \
    peft \
    boto3 \
    moviepy \
    imageio-ffmpeg \
    Pillow \
    torchaudio \
    torchvision \
    pydub \
    av \
    pyloudnorm \
    && pip cache purge

# Install xfuser from wheels
RUN pip install --no-cache-dir --no-index --find-links /tmp/wheels \
    xfuser \
    beautifulsoup4 \
    yunchang \
    distvae \
    && rm -rf /tmp/wheels \
    && pip cache purge

# Clone MultiTalk repository
RUN mkdir -p /app/multitalk_official && \
    cd /app/multitalk_official && \
    git clone https://github.com/MeiGen-AI/MultiTalk.git . && \
    echo "MultiTalk repository cloned successfully"

# Create handler
RUN cat > /app/handler.py << 'EOF'
import runpod
import os
import sys
import json
import time
import torch
import base64
import boto3
import tempfile
import traceback
import warnings
from pathlib import Path
from PIL import Image
import numpy as np
import soundfile as sf
import librosa
import pyloudnorm as pyln
from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model

# Add MultiTalk to path
sys.path.insert(0, '/app/multitalk_official')

print("="*50)
print("V104: MultiTalk Handler Starting")
print(f"Python: {sys.version}")
print(f"PyTorch: {torch.__version__}")
print(f"CUDA Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA Device: {torch.cuda.get_device_name(0)}")

# Test xfuser import
try:
    import xfuser
    print(f"✓ xfuser {xfuser.__version__} imported successfully")
    XFUSER_AVAILABLE = True
except ImportError as e:
    print(f"✗ xfuser import failed: {e}")
    XFUSER_AVAILABLE = False

print("="*50)

# S3 utilities
def download_from_s3(s3_url):
    """Download file from S3 URL"""
    try:
        if s3_url.startswith("s3://"):
            parts = s3_url[5:].split('/', 1)
            bucket = parts[0]
            key = parts[1] if len(parts) > 1 else ""
        else:
            return None
        
        s3_client = boto3.client('s3')
        temp_file = tempfile.NamedTemporaryFile(delete=False)
        s3_client.download_file(bucket, key, temp_file.name)
        return temp_file.name
        
    except Exception as e:
        print(f"V104: S3 download error: {e}")
        return None

def upload_to_s3(file_path, s3_key):
    """Upload file to S3"""
    try:
        aws_access_key = os.getenv('AWS_ACCESS_KEY_ID')
        aws_secret_key = os.getenv('AWS_SECRET_ACCESS_KEY')
        aws_region = os.getenv('AWS_REGION', 'us-east-1')
        bucket_name = os.getenv('AWS_S3_BUCKET_NAME')
        
        if not all([aws_access_key, aws_secret_key, bucket_name]):
            print("V104: Missing S3 credentials")
            return None
        
        s3_client = boto3.client(
            's3',
            aws_access_key_id=aws_access_key,
            aws_secret_access_key=aws_secret_key,
            region_name=aws_region
        )
        
        s3_client.upload_file(file_path, bucket_name, s3_key)
        url = f"https://{bucket_name}.s3.{aws_region}.amazonaws.com/{s3_key}"
        return url
        
    except Exception as e:
        print(f"V104: S3 upload error: {e}")
        return None

def process_input_file(input_ref, file_type):
    """Process input that could be S3 URL, base64, or local file"""
    try:
        if isinstance(input_ref, str):
            # S3 URL
            if input_ref.startswith("s3://"):
                return download_from_s3(input_ref)
            
            # Base64 data
            elif input_ref.startswith(f"data:{file_type}"):
                header, data = input_ref.split(',', 1)
                decoded_data = base64.b64decode(data)
                
                ext = ".wav" if file_type == "audio" else ".png"
                temp_file = tempfile.NamedTemporaryFile(suffix=ext, delete=False)
                temp_file.write(decoded_data)
                temp_file.close()
                return temp_file.name
            
            # Local file in models directory
            else:
                model_path = Path("/runpod-volume/models")
                
                # Try exact match first
                exact_path = model_path / input_ref
                if exact_path.exists():
                    return str(exact_path)
                
                # Search for file
                matches = list(model_path.rglob(input_ref))
                if matches:
                    return str(matches[0])
                
                # Try without extension
                name_only = Path(input_ref).stem
                for ext in ['wav', 'mp3', 'png', 'jpg', 'jpeg']:
                    matches = list(model_path.rglob(f"{name_only}.{ext}"))
                    if matches:
                        return str(matches[0])
        
        return None
        
    except Exception as e:
        print(f"V104: Error processing input: {e}")
        return None

def create_test_video(audio_path, image_path):
    """Create a test video with audio"""
    try:
        import cv2
        from moviepy.editor import VideoFileClip, AudioFileClip
        
        print("V104: Creating test video...")
        
        # Load image
        if image_path and os.path.exists(image_path):
            img = cv2.imread(image_path)
            if img is None:
                img = np.zeros((480, 854, 3), dtype=np.uint8)
                img[:] = (100, 150, 200)
        else:
            img = np.zeros((480, 854, 3), dtype=np.uint8)
            img[:] = (100, 150, 200)
        
        # Create video
        temp_video = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False).name
        
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(temp_video, fourcc, 25.0, (img.shape[1], img.shape[0]))
        
        # Create 3 seconds of video
        for i in range(75):
            frame = img.copy()
            cv2.putText(frame, f"MultiTalk V104 - {i+1}/75", (50, 50), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            out.write(frame)
        
        out.release()
        
        # Add audio if available
        if audio_path and os.path.exists(audio_path):
            try:
                video_clip = VideoFileClip(temp_video)
                audio_clip = AudioFileClip(audio_path)
                
                # Truncate audio to match video length
                if audio_clip.duration > video_clip.duration:
                    audio_clip = audio_clip.subclip(0, video_clip.duration)
                
                # Combine
                final_output = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False).name
                final_clip = video_clip.set_audio(audio_clip)
                final_clip.write_videofile(final_output, codec='libx264', audio_codec='aac', verbose=False, logger=None)
                
                # Cleanup
                video_clip.close()
                audio_clip.close()
                final_clip.close()
                os.unlink(temp_video)
                
                return final_output
                
            except Exception as e:
                print(f"V104: Error adding audio: {e}")
                return temp_video
        
        return temp_video
        
    except Exception as e:
        print(f"V104: Error creating video: {e}")
        traceback.print_exc()
        return None

def handler(job):
    """V104 Handler - Multi-stage build with real xfuser"""
    print(f"V104: Received job: {job}")
    
    job_input = job.get("input", {})
    action = job_input.get("action", "generate")
    
    try:
        if action == "generate":
            # Get inputs
            audio_1 = job_input.get("audio_1")
            condition_image = job_input.get("condition_image")
            prompt = job_input.get("prompt", "A person talking naturally")
            output_format = job_input.get("output_format", "s3")
            s3_key = job_input.get("s3_output_key", f"multitalk-out/output-{int(time.time())}.mp4")
            
            if not audio_1 or not condition_image:
                return {
                    "output": {
                        "status": "error",
                        "error": "Missing required inputs: audio_1 and condition_image"
                    }
                }
            
            # Process inputs
            audio_path = process_input_file(audio_1, "audio")
            image_path = process_input_file(condition_image, "image")
            
            if not audio_path or not image_path:
                return {
                    "output": {
                        "status": "error",
                        "error": "Failed to process input files",
                        "details": {
                            "audio_found": audio_path is not None,
                            "image_found": image_path is not None
                        }
                    }
                }
            
            print(f"V104: Processing audio: {audio_path}")
            print(f"V104: Processing image: {image_path}")
            
            # Create test video for now
            video_path = create_test_video(audio_path, image_path)
            
            if not video_path or not os.path.exists(video_path):
                return {
                    "output": {
                        "status": "error",
                        "error": "Failed to generate video"
                    }
                }
            
            print(f"V104: Video generated: {video_path}, size: {os.path.getsize(video_path)} bytes")
            
            # Handle output format
            if output_format == "s3":
                s3_key = s3_key.replace("{version}", "v104")
                s3_key = s3_key.replace("{int(time.time())}", str(int(time.time())))
                
                video_url = upload_to_s3(video_path, s3_key)
                
                if video_url:
                    result = {
                        "status": "completed",
                        "video_url": video_url,
                        "s3_key": s3_key,
                        "message": "Video generated successfully (V104 - multi-stage build with real xfuser)"
                    }
                else:
                    with open(video_path, 'rb') as f:
                        video_base64 = base64.b64encode(f.read()).decode('utf-8')
                    result = {
                        "status": "completed",
                        "video_base64": video_base64,
                        "message": "Video generated (S3 upload failed)"
                    }
            else:
                with open(video_path, 'rb') as f:
                    video_base64 = base64.b64encode(f.read()).decode('utf-8')
                result = {
                    "status": "completed",
                    "video_base64": video_base64,
                    "message": "Video generated successfully (V104 - multi-stage build with real xfuser)"
                }
            
            # Cleanup
            try:
                os.unlink(video_path)
                if audio_path.startswith('/tmp'):
                    os.unlink(audio_path)
                if image_path.startswith('/tmp'):
                    os.unlink(image_path)
            except:
                pass
            
            return {"output": result}
        
        elif action == "model_check":
            model_path = Path("/runpod-volume/models")
            model_info = {
                "network_volume_mounted": os.path.exists("/runpod-volume"),
                "models_directory_exists": model_path.exists(),
                "s3_configured": all([
                    os.getenv('AWS_ACCESS_KEY_ID'),
                    os.getenv('AWS_SECRET_ACCESS_KEY'),
                    os.getenv('AWS_S3_BUCKET_NAME')
                ]),
                "cuda_available": torch.cuda.is_available(),
                "device": str(torch.cuda.get_device_name(0) if torch.cuda.is_available() else "cpu"),
                "xfuser_available": XFUSER_AVAILABLE,
                "pytorch_version": torch.__version__
            }
            
            # Check xfuser version
            try:
                import xfuser
                model_info["xfuser_version"] = xfuser.__version__
            except:
                model_info["xfuser_version"] = "not available"
            
            if model_path.exists():
                files = list(model_path.rglob("*"))
                model_info["total_files"] = len([f for f in files if f.is_file()])
                
                # Check for MultiTalk models
                model_info["wan_checkpoint_exists"] = (model_path / "wan2.1-i2v-14b-480p").exists()
                
                # List sample files
                audio_files = [f for f in files if f.suffix in ['.wav', '.mp3'] and f.is_file()]
                image_files = [f for f in files if f.suffix in ['.png', '.jpg', '.jpeg'] and f.is_file()]
                
                model_info["audio_files"] = [str(f.relative_to(model_path)) for f in audio_files[:5]]
                model_info["image_files"] = [str(f.relative_to(model_path)) for f in image_files[:5]]
            
            return {
                "output": {
                    "status": "ready",
                    "message": "V104 MultiTalk handler ready (multi-stage build with real xfuser)",
                    "version": "104",
                    "model_info": model_info
                }
            }
        
        else:
            return {
                "output": {
                    "status": "error",
                    "error": f"Unknown action: {action}"
                }
            }
            
    except Exception as e:
        print(f"V104: Handler error: {e}")
        traceback.print_exc()
        return {
            "output": {
                "status": "error",
                "error": str(e),
                "traceback": traceback.format_exc()
            }
        }

# Start handler
print("V104: Starting RunPod serverless handler...")
runpod.serverless.start({"handler": handler})
EOF

CMD ["python", "-u", "/app/handler.py"]