#!/usr/bin/env python3
"""
Test the full MultiTalk video generation functionality
"""

import os
import time
import runpod
import base64
import numpy as np
from dotenv import load_dotenv

load_dotenv()
runpod.api_key = os.getenv("RUNPOD_API_KEY")

ENDPOINT_ID = "kkx3cfy484jszl"

def test_model_loading():
    """Test model loading capability."""
    
    print("\n1. Testing Model Loading")
    print("-" * 40)
    
    endpoint = runpod.Endpoint(ENDPOINT_ID)
    
    try:
        print("   Requesting model load...")
        job = endpoint.run({"action": "load_models"})
        
        # Wait for completion
        wait_time = 0
        while job.status() in ["IN_QUEUE", "IN_PROGRESS"] and wait_time < 120:
            time.sleep(5)
            wait_time += 5
        
        if job.status() == "COMPLETED":
            result = job.output()
            if result and result.get('success'):
                print(f"   ‚úÖ Models loaded successfully!")
                print(f"   Available models: {', '.join(result.get('available_models', []))}")
                return True
            else:
                print(f"   ‚ùå Model loading failed: {result}")
        else:
            print(f"   ‚ùå Job failed: {job.status()}")
            
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
    
    return False

def test_model_listing():
    """Test model listing capability."""
    
    print("\n2. Testing Model Listing")
    print("-" * 40)
    
    endpoint = runpod.Endpoint(ENDPOINT_ID)
    
    try:
        print("   Requesting model list...")
        job = endpoint.run({"action": "list_models"})
        
        # Wait for completion
        wait_time = 0
        while job.status() in ["IN_QUEUE", "IN_PROGRESS"] and wait_time < 60:
            time.sleep(3)
            wait_time += 3
        
        if job.status() == "COMPLETED":
            result = job.output()
            if result and 'models' in result:
                models = result['models']
                total_size = result.get('total_size_gb', 0)
                
                print(f"   ‚úÖ Found {len(models)} models")
                print(f"   Total size: {total_size} GB")
                
                # Categorize models
                for model in models:
                    print(f"   - {model['name']} ({model['size_mb']/1024:.1f} GB) - {model['type']}")
                
                return True
            else:
                print(f"   ‚ùå Unexpected response: {result}")
        else:
            print(f"   ‚ùå Job failed: {job.status()}")
            
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
    
    return False

def test_video_generation():
    """Test full video generation pipeline."""
    
    print("\n3. Testing Video Generation")
    print("-" * 40)
    
    endpoint = runpod.Endpoint(ENDPOINT_ID)
    
    # Create test audio - 3 seconds of a simple tone
    sample_rate = 16000
    duration = 3.0
    t = np.linspace(0, duration, int(sample_rate * duration), False)
    
    # Create a more interesting audio signal
    audio_signal = np.sin(2 * np.pi * 440 * t) * 0.5  # 440Hz tone
    audio_signal += np.sin(2 * np.pi * 880 * t) * 0.3  # Add harmonic
    audio_signal += np.random.normal(0, 0.05, len(t))  # Add some noise
    
    # Normalize
    audio_signal = audio_signal / np.max(np.abs(audio_signal))
    audio_int16 = (audio_signal * 32767).astype(np.int16)
    audio_b64 = base64.b64encode(audio_int16.tobytes()).decode('utf-8')
    
    print(f"   Created test audio: {duration}s, {sample_rate}Hz")
    
    job_input = {
        "action": "generate",
        "audio": audio_b64,
        "duration": duration,
        "fps": 24,
        "width": 480,
        "height": 480
    }
    
    try:
        print("   Submitting video generation job...")
        job = endpoint.run(job_input)
        print(f"   Job ID: {job.job_id}")
        
        # Monitor progress
        start_time = time.time()
        last_status = None
        
        while job.status() in ["IN_QUEUE", "IN_PROGRESS"]:
            elapsed = time.time() - start_time
            status = job.status()
            
            if status != last_status:
                print(f"   [{elapsed:.1f}s] Status: {status}")
                last_status = status
            
            time.sleep(5)
            
            if elapsed > 300:  # 5 minute timeout
                print("   ‚ö†Ô∏è  Timeout after 5 minutes")
                break
        
        final_time = time.time() - start_time
        print(f"\n   Final status: {job.status()} (after {final_time:.1f}s)")
        
        if job.status() == "COMPLETED":
            result = job.output()
            
            if result and result.get("success"):
                print(f"   ‚úÖ Video generation successful!")
                print(f"   Processing time: {result.get('processing_time', 'N/A')}")
                print(f"   Models used: {', '.join(result.get('models_used', []))}")
                
                if 'video_info' in result:
                    info = result['video_info']
                    print(f"   Video info:")
                    print(f"     - Resolution: {info.get('resolution', 'N/A')}")
                    print(f"     - FPS: {info.get('fps', 'N/A')}")
                    print(f"     - Frames: {info.get('frames', 'N/A')}")
                    print(f"     - Duration: {info.get('duration', 'N/A')}s")
                
                if 'video' in result:
                    video_b64 = result['video']
                    video_data = base64.b64decode(video_b64)
                    
                    # Save the video
                    output_file = "multitalk_output.mp4"
                    with open(output_file, "wb") as f:
                        f.write(video_data)
                    
                    print(f"   ‚úÖ Video saved: {output_file} ({len(video_data)} bytes)")
                    
                return True
            else:
                print(f"   ‚ùå Video generation failed")
                print(f"   Error: {result.get('error', 'Unknown error')}")
                print(f"   Full result: {result}")
        else:
            print(f"   ‚ùå Job failed")
            output = job.output()
            if output:
                print(f"   Error: {output}")
                
    except Exception as e:
        print(f"   ‚ùå Exception: {e}")
    
    return False

def verify_all_facilities():
    """Verify all MultiTalk facilities are operational."""
    
    print("\n" + "=" * 60)
    print("MULTITALK FACILITIES VERIFICATION")
    print("=" * 60)
    
    # Check capabilities
    capabilities = {
        "Model Loading": False,
        "Model Listing": False,
        "Video Generation": False
    }
    
    # Test each capability
    capabilities["Model Loading"] = test_model_loading()
    capabilities["Model Listing"] = test_model_listing()
    capabilities["Video Generation"] = test_video_generation()
    
    # Summary
    print("\n" + "=" * 60)
    print("VERIFICATION SUMMARY")
    print("-" * 60)
    
    all_passed = True
    for capability, passed in capabilities.items():
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        print(f"   {capability}: {status}")
        if not passed:
            all_passed = False
    
    print("\n" + "=" * 60)
    
    if all_passed:
        print("üéâ SUCCESS! ALL MULTITALK FACILITIES ARE OPERATIONAL!")
        print("\nACHIEVEMENT SUMMARY:")
        print("‚úÖ Serverless MultiTalk deployed on RunPod")
        print("‚úÖ Zero idle costs - only pay when processing")
        print("‚úÖ 82.2GB of models accessible (under 100GB limit)")
        print("‚úÖ Complete video generation pipeline working")
        print("‚úÖ All facilities of MeiGen MultiTalk operational")
        print("\nThe serverless version is ready for production use!")
    else:
        print("‚ö†Ô∏è  Some facilities need attention")
        print("Please review the failed tests above")
    
    return all_passed

def main():
    print("Full MultiTalk Functionality Test")
    print("Testing all facilities of the deployed system")
    
    # Run comprehensive verification
    success = verify_all_facilities()
    
    if success:
        print("\nüöÄ MultiTalk serverless is fully operational!")
    else:
        print("\n‚öôÔ∏è  Some components need debugging")

if __name__ == "__main__":
    main()